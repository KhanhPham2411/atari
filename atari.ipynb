{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "atari.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM1awmrjMXnWsdXmLZLhJeG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KhanhPham2411/atari/blob/master/atari.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpyJJgpltusi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://github.com/KhanhPham2411/atari/archive/master.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FozMtqwqt3Gw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip master.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6isSs8hZt67e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd atari-master/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCDaANdzthvF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8d21bd5b-0350-4865-f96a-b695a4b829e2"
      },
      "source": [
        "import gym\n",
        "import argparse\n",
        "import numpy as np\n",
        "import atari_py\n",
        "from game_models.ddqn_game_model import DDQNTrainer, DDQNSolver\n",
        "from game_models.ge_game_model import GETrainer, GESolver\n",
        "from gym_wrappers import MainGymWrapper\n",
        "import easydict\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-h4cRIVjtilV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "FRAMES_IN_OBSERVATION = 4\n",
        "FRAME_SIZE = 84\n",
        "INPUT_SHAPE = (FRAMES_IN_OBSERVATION, FRAME_SIZE, FRAME_SIZE)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skvpTB1Jj6uw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "16378f90-5cd2-475d-f6df-948b69d6ff95"
      },
      "source": [
        "# fix https://github.com/keras-team/keras/issues/13684\n",
        "import tensorflow as tf\n",
        "import keras.backend.tensorflow_backend as tfback\n",
        "\n",
        "print(\"tf.__version__ is\", tf.__version__)\n",
        "print(\"tf.keras.__version__ is:\", tf.keras.__version__)\n",
        "\n",
        "def _get_available_gpus():\n",
        "    if tfback._LOCAL_DEVICES is None:\n",
        "        devices = tf.config.list_logical_devices()\n",
        "        tfback._LOCAL_DEVICES = [x.name for x in devices]\n",
        "    return [x for x in tfback._LOCAL_DEVICES if 'device:gpu' in x.lower()]\n",
        "\n",
        "tfback._get_available_gpus = _get_available_gpus"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.__version__ is 2.2.0\n",
            "tf.keras.__version__ is: 2.3.0-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3pUp1H-tUlA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Atari:\n",
        "\n",
        "    def __init__(self):\n",
        "        game_name, game_mode, render, total_step_limit, total_run_limit, clip = self._args()\n",
        "        env_name = game_name + \"Deterministic-v4\"  # Handles frame skipping (4) at every iteration\n",
        "        env = MainGymWrapper.wrap(gym.make(env_name))\n",
        "        self._main_loop(self._game_model(game_mode, game_name, env.action_space.n), env, render, total_step_limit, total_run_limit, clip)\n",
        "\n",
        "    def _main_loop(self, game_model, env, render, total_step_limit, total_run_limit, clip):\n",
        "        if isinstance(game_model, GETrainer):\n",
        "            game_model.genetic_evolution(env)\n",
        "\n",
        "        run = 0\n",
        "        total_step = 0\n",
        "        while True:\n",
        "            if total_run_limit is not None and run >= total_run_limit:\n",
        "                print(\"Reached total run limit of: \" + str(total_run_limit))\n",
        "                exit(0)\n",
        "\n",
        "            run += 1\n",
        "            current_state = env.reset()\n",
        "            step = 0\n",
        "            score = 0\n",
        "            while True:\n",
        "                if total_step >= total_step_limit:\n",
        "                    print(\"Reached total step limit of: \" + str(total_step_limit))\n",
        "                    exit(0)\n",
        "                total_step += 1\n",
        "                step += 1\n",
        "\n",
        "                if render:\n",
        "                    env.render()\n",
        "\n",
        "                action = game_model.move(current_state)\n",
        "                next_state, reward, terminal, info = env.step(action)\n",
        "                if clip:\n",
        "                    np.sign(reward)\n",
        "                score += reward\n",
        "                game_model.remember(current_state, action, reward, next_state, terminal)\n",
        "                current_state = next_state\n",
        "\n",
        "                game_model.step_update(total_step)\n",
        "\n",
        "                if terminal:\n",
        "                    game_model.save_run(score, step, run)\n",
        "                    break\n",
        "\n",
        "    def _args(self):\n",
        "        # parser = argparse.ArgumentParser()\n",
        "        # available_games = list((''.join(x.capitalize() or '_' for x in word.split('_')) for word in atari_py.list_games()))\n",
        "        # parser.parse_known_args(\"-g\", \"--game\", help=\"Choose from available games: \" + str(available_games) + \". Default is 'breakout'.\", default=\"Breakout\")\n",
        "        # parser.parse_known_args(\"-m\", \"--mode\", help=\"Choose from available modes: ddqn_train, ddqn_test, ge_train, ge_test. Default is 'ddqn_training'.\", default=\"ddqn_training\")\n",
        "        # parser.parse_known_args(\"-r\", \"--render\", help=\"Choose if the game should be rendered. Default is 'False'.\", default=False, type=bool)\n",
        "        # parser.parse_known_args(\"-tsl\", \"--total_step_limit\", help=\"Choose how many total steps (frames visible by agent) should be performed. Default is '5000000'.\", default=5000000, type=int)\n",
        "        # parser.parse_known_args(\"-trl\", \"--total_run_limit\", help=\"Choose after how many runs we should stop. Default is None (no limit).\", default=None, type=int)\n",
        "        # parser.parse_known_args(\"-c\", \"--clip\", help=\"Choose whether we should clip rewards to (0, 1) range. Default is 'True'\", default=True, type=bool)\n",
        "\n",
        "        args = params\n",
        "\n",
        "        game_mode = args.mode\n",
        "        game_name = args.game\n",
        "        render = args.render\n",
        "        total_step_limit = args.total_step_limit\n",
        "        total_run_limit = args.total_run_limit\n",
        "        clip = args.clip\n",
        "        print(\"Selected game: \" + str(game_name))\n",
        "        print(\"Selected mode: \" + str(game_mode))\n",
        "        print(\"Should render: \" + str(render))\n",
        "        print(\"Should clip: \" + str(clip))\n",
        "        print(\"Total step limit: \" + str(total_step_limit))\n",
        "        print(\"Total run limit: \" + str(total_run_limit))\n",
        "        return game_name, game_mode, render, total_step_limit, total_run_limit, clip\n",
        "\n",
        "    def _game_model(self, game_mode,game_name, action_space):\n",
        "        if game_mode == \"ddqn_training\":\n",
        "            return DDQNTrainer(game_name, INPUT_SHAPE, action_space)\n",
        "        elif game_mode == \"ddqn_testing\":\n",
        "            return DDQNSolver(game_name, INPUT_SHAPE, action_space)\n",
        "        elif game_mode == \"ge_training\":\n",
        "            return GETrainer(game_name, INPUT_SHAPE, action_space)\n",
        "        elif game_mode == \"ge_testing\":\n",
        "            return GESolver(game_name, INPUT_SHAPE, action_space)\n",
        "        else:\n",
        "            print(\"Unrecognized mode. Use --help\")\n",
        "            exit(1)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E8XhopBkgiHn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "93eae34e-bf19-4f3f-8c53-3246453ab533"
      },
      "source": [
        "params = easydict.EasyDict({\n",
        "    \"game\": \"Breakout\",\n",
        "    \"mode\": \"ddqn_training\",\n",
        "    \"render\": False,\n",
        "    \"total_step_limit\": 5000000,\n",
        "    \"total_run_limit\": None,\n",
        "    \"clip\": True\n",
        "})\n",
        "\n",
        "available_games = list((''.join(x.capitalize() or '_' for x in word.split('_')) for word in atari_py.list_games()))\n",
        "print(\"Choose from available games: \" + str(available_games) + \". Default is 'breakout'.\")\n",
        "print(\"Choose from available modes: [ddqn_train, ddqn_test, ge_train, ge_test]. Default is 'ddqn_training'.\")\n",
        "print(\"Choose if the game should be rendered. Default is 'False'.\")\n",
        "print(\"Choose how many total steps (frames visible by agent) should be performed. Default is '5000000'.\")\n",
        "print(\"Choose after how many runs we should stop. Default is None (no limit).\")\n",
        "print(\"Choose whether we should clip rewards to (0, 1) range. Default is 'True'\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Choose from available games: ['JourneyEscape', 'Jamesbond', 'Pooyan', 'RoadRunner', 'Robotank', 'Skiing', 'CrazyClimber', 'Riverraid', 'Tutankham', 'Carnival', 'PrivateEye', 'NameThisGame', 'Alien', 'Asteroids', 'MsPacman', 'Pitfall', 'MontezumaRevenge', 'Kaboom', 'DemonAttack', 'ElevatorAction', 'BattleZone', 'UpNDown', 'SpaceInvaders', 'TimePilot', 'Gopher', 'Berzerk', 'Bowling', 'Qbert', 'Pong', 'Krull', 'Assault', 'BeamRider', 'Atlantis', 'Enduro', 'Venture', 'Phoenix', 'Defender', 'ChopperCommand', 'Centipede', 'AirRaid', 'Hero', 'VideoPinball', 'Solaris', 'YarsRevenge', 'Gravitar', 'KungFuMaster', 'Amidar', 'Zaxxon', 'Asterix', 'Adventure', 'Seaquest', 'IceHockey', 'DoubleDunk', 'Frostbite', 'Tennis', 'Boxing', 'StarGunner', 'Kangaroo', 'Freeway', 'FishingDerby', 'WizardOfWor', 'BankHeist', 'Breakout']. Default is 'breakout'.\n",
            "Choose from available modes: [ddqn_train, ddqn_test, ge_train, ge_test]. Default is 'ddqn_training'.\n",
            "Choose if the game should be rendered. Default is 'False'.\n",
            "Choose how many total steps (frames visible by agent) should be performed. Default is '5000000'.\n",
            "Choose after how many runs we should stop. Default is None (no limit).\n",
            "Choose whether we should clip rewards to (0, 1) range. Default is 'True'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpNGe-VnwOVY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(__name__)\n",
        "if __name__ == \"__main__\":\n",
        "    Atari()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}